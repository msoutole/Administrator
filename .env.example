# GitHub Personal Access Token (required for API access)
# Create one at: https://github.com/settings/tokens
GITHUB_TOKEN=your_github_token_here

# AI Provider Configuration
# Choose your AI provider: openai, anthropic, or gemini
AI_PROVIDER=openai

# OpenAI API Key (for provider=openai)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (for provider=anthropic)
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini API Key (for provider=gemini)
# Get your key at: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# AI Model (optional - uses provider default if not set)
# OpenAI: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
# Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
# Gemini: gemini-1.5-pro, gemini-1.5-flash
AI_MODEL=

# AI Max Tokens (optional - default: 2000)
AI_MAX_TOKENS=2000

# AI Temperature (optional - default: 0.7, range: 0.0-2.0)
AI_TEMPERATURE=0.7

# Analysis Configuration
# Minimum quality score threshold (0-100)
MIN_QUALITY_SCORE=50

# Maximum repositories to analyze per batch
MAX_REPOS_PER_BATCH=10

# Enable verbose logging
VERBOSE=false

# Cache directory for analysis results
CACHE_DIR=.cache/administrator

# Analysis timeout in milliseconds
ANALYSIS_TIMEOUT=30000
